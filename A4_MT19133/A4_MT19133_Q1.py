# -*- coding: utf-8 -*-
"""SML_A4_1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1RCVj2MH3QBRpceumokeP2MGBicHaWHFN
"""

import pandas as pd
f = open("Dataset.data", "r")
var=(f.read())
rep="\\"
var=var.replace(rep,"")
var = var.split()
var1=[]
for i in range(0,len(var)):
  var1.append(float(var[i]))

data = [var1[i * 14:(i + 1) * 14] for i in range((len(var1) + 13) // 14 )] 
print((data))


df = pd.DataFrame(data, columns=["CRIM","ZN","NDUS","CHAS","NOX","RM","AGE","DIS","RAD","TAX","PTRATIO","B","LSTAT","MEDV"])
df_x=df[["CRIM","ZN","NDUS","CHAS","NOX","RM","AGE","DIS","RAD","TAX","PTRATIO","B","LSTAT"]]
df_y=df["MEDV"]
#df_x=(df_x-df_x.mean())/df_x.std()
#df_y=(df_y-df_y.mean())/df_y.std()

#print(df_x)
#print(df_y)

#Dividing the data in test-train 
from sklearn.model_selection import train_test_split

xTrain, xTest, yTrain, yTest = train_test_split(df_x, df_y, test_size = 0.2, random_state = 5)

print((df_x.shape))

##Perform Linear regression for all features and compute the RMSE for training
##as well as the testing set. (Note: There is no need to perform k-fold
##cross-validation for this part.)
import numpy as np
xTrain["ones"]=1
xTrain=xTrain.transpose()

yTrain=pd.DataFrame(yTrain)

Temp=np.linalg.pinv(np.dot(xTrain,xTrain.transpose()))
Temp1=np.dot(xTrain,yTrain)
w=Temp.dot(Temp1)
#print(w.shape)
#print(w)

######### RMSE for training #########
import math
w=w.T
y_estimated=np.dot(w,xTrain)
#print(yTrain)
#print(y_estimated)
yTrain=yTrain.to_numpy()
y_estimated=y_estimated.T
MSE=0
for i in range(0,len(yTrain)):
  MSE=MSE+((yTrain[i]-y_estimated[i])**2) 

MSE=math.sqrt(MSE/len(yTrain))
print(MSE)

######### RMSE for testing #########

yTest=pd.DataFrame(yTest)
xTest["ones"]=1
xTest=xTest.transpose()

import math

y_estimated=np.dot(w,xTest)

yTest=yTest.to_numpy()
y_estimated=y_estimated.T
MSE=0
for i in range(0,len(yTest)):
  MSE=MSE+((yTest[i]-y_estimated[i])**2) 

MSE=math.sqrt(MSE/len(yTest))
print(MSE)

print(type(yTrain))

###Select the feature named â€˜LSTATâ€™ for polynomial regression###
###Perform k-fold cross-validation for k=5 on the training dataset. (Note: You can
###not use any inbuilt library to implement k-fold cross-validation.)

#Temp=np.linalg.pinv(np.dot(myTrain,myTrain.transpose()))
#Temp1=np.dot(myTrain,yTrain)
#w=np.dot(Temp,Temp1)
#print(yTrain.shape)
#w=w.T

import math
yTrain1=pd.DataFrame(yTrain)  
myTrain1=xTrain[12:14]
print(myTrain1)
E=[]
myTrain1=myTrain1.transpose()
for i in range(0,5):
  xTrainValid=pd.DataFrame()
  yTrainValid=pd.DataFrame()
  xTestValid=pd.DataFrame()
  yTestValid=pd.DataFrame()

  if i == 0:
    t1=0
    t2=80
  else:
    t1=t2
    t2=t1+80
  xTestValid=myTrain1[t1:t2]
  yTestValid=yTrain1[t1:t2]

  for j in range(0,400):
    if not(j>=t1 and j < t2):
      xTrainValid=xTrainValid.append(myTrain1.iloc[j])
      yTrainValid=yTrainValid.append(yTrain1.iloc[j])
  

  xTrain1=xTrainValid.transpose()

  Temp=np.linalg.pinv(np.dot(xTrain1,xTrain1.transpose()))
  Temp1=np.dot(xTrain1,yTrainValid)
  w=Temp.dot(Temp1)


  w=w.T
  y_estimated=np.dot(w,xTestValid.transpose())
  #print(yTrain)
  #print(y_estimated)
  yTestValid=yTestValid.to_numpy()
  y_estimated=y_estimated.T
  MSE=0
  for i in range(0,len(yTestValid)):
    MSE=MSE+((yTestValid[i]-y_estimated[i])**2) 

  MSE=math.sqrt(MSE/len(yTestValid))
  print(MSE)
  E.append(MSE)

E_avg=sum(E)/len(E)

print("E_avg",E_avg)

###(e)Perform step (d) for different degrees of polynomials using Polynomial
###Regression (Ex. For degree=1 perform 5-fold cross-validation, For degree=2,
###perform 5-fold cross-validation and so on.)
import math
  
#degree=input("Please enter degree of the polynomial")
#degree=int(degree)
Validation=[]
Training=[]
for Deg in range(1,25):
  yTrain1=pd.DataFrame(yTrain)  
  myTrain1=xTrain[12:13]
  myTrain1=list(myTrain1.iloc[0])

  df=pd.DataFrame()
  for d in range(Deg,-1,-1):
    l=(np.array(myTrain1)**d)
    df=df.append(pd.DataFrame(l).T)

  #print(type(df))
  myTrain1=df
  #print(myTrain1)

  #print(myTrain1)
  E=[]
  E1=[]
  myTrain1=myTrain1.transpose()
  for i in range(0,5):
    xTrainValid=pd.DataFrame()
    yTrainValid=pd.DataFrame()
    xTestValid=pd.DataFrame()
    yTestValid=pd.DataFrame()

    if i == 0:
      t1=0
      t2=80
    else:
      t1=t2
      t2=t1+80
    xTestValid=myTrain1[t1:t2]
    yTestValid=yTrain1[t1:t2]

    for j in range(0,400):
      if not(j>=t1 and j < t2):
        xTrainValid=xTrainValid.append(pd.DataFrame(myTrain1.iloc[j]).transpose())
        #print(xTrainValid)
        #yTrainValid=yTrainValid.append(pd.DataFrame(yTrain1.iloc[j]).transpose())
        #xTrainValid=xTrainValid.append(myTrain1.iloc[j])
        yTrainValid=yTrainValid.append(yTrain1.iloc[j])
    

    xTrain1=xTrainValid.transpose()

    Temp=np.linalg.pinv(np.dot(xTrain1,xTrain1.transpose()))
    Temp1=np.dot(xTrain1,yTrainValid)
    w=Temp.dot(Temp1)


    w=w.T
    y_estimated=np.dot(w,xTestValid.transpose())
    #print(yTrain)
    #print(y_estimated)
    yTestValid=yTestValid.to_numpy()
    y_estimated=y_estimated.T
    MSE=0
    for i in range(0,len(yTestValid)):
      MSE=MSE+((yTestValid[i]-y_estimated[i])**2) 

    MSE=math.sqrt(MSE/len(yTestValid))
    #print(MSE)
    E.append(MSE)

    ############################### # 
    y_estimated1=np.dot(w,xTrainValid.transpose())
    yTrainValid=yTrainValid.to_numpy()
    y_estimated1=y_estimated1.T
    MSE=0
    for i in range(0,len(yTrainValid)):
      MSE=MSE+((yTrainValid[i]-y_estimated1[i])**2) 

    MSE=math.sqrt(MSE/len(yTrainValid))
    #print(MSE)
    E1.append(MSE)




  E_avg=sum(E)/len(E)
  print(Deg)
  print("E_avg_k_cross_fold",E_avg)
  Validation.append(E_avg)
  
  E_avg1=sum(E1)/len(E1)
  
  print("E_train",E_avg1)
  Training.append(E_avg1)

import matplotlib.pyplot as plt 
x1 = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24] 
plt.plot(x1, Training, label = "Training Error") 
 
plt.plot(x1, Validation, label = "Validation Error") 
  
plt.xlabel('x - axis') 
plt.ylabel('y - axis') 
plt.title('Training & Testing Errors') 
  
plt.legend() 

plt.show()

###Choose the degree of a polynomial with the least mean validation RMSE and
#use that degree of polynomial to perform final regression on the whole
#training dataset (i.e., 80% dataset). State the RMSE of the test dataset (i.e.,
#20% dataset).

yTrain1=pd.DataFrame(yTrain)  
myTrain1=xTrain[12:13]
myTrain1=list(myTrain1.iloc[0])

df=pd.DataFrame()
for d in range(4,-1,-1):
  l=(np.array(myTrain1)**d)
  df=df.append(pd.DataFrame(l).T)

myTrain1=df
Temp=np.linalg.pinv(np.dot(myTrain1,myTrain1.transpose()))
Temp1=np.dot(myTrain1,yTrain1)
w=Temp.dot(Temp1)

w=w.T
y_estimated=np.dot(w,myTrain1)
#print(yTrain)
#print(y_estimated)
yTrain1=yTrain1.to_numpy()
y_estimated=y_estimated.T
MSE=0
for i in range(0,len(yTrain1)):
  MSE=MSE+((yTrain1[i]-y_estimated[i])**2) 

MSE=math.sqrt(MSE/len(yTrain1))
print("Training error on complete training set ",MSE)

####Testing Error#####
yTest=pd.DataFrame(yTest)  
myTest1=xTest[12:13]
myTest1=list(myTest1.iloc[0])

df=pd.DataFrame()
for d in range(4,-1,-1):
  l=(np.array(myTest1)**d)
  df=df.append(pd.DataFrame(l).T)

myTest1=df



y_estimated=np.dot(w,myTest1)
y_estimated=y_estimated.T
yTest=yTest.transpose()
MSE=0
for i in range(0,len(yTest)):
  MSE=MSE+((yTest[i]-y_estimated[i])**2) 

MSE=math.sqrt(MSE/len(yTest))

print(MSE)