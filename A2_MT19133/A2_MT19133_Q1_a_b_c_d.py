# -*- coding: utf-8 -*-
"""a_b_c_d.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1sG_459pMuvOs3lFLiBSnwGgnBTpFo2hX
"""

me kiimport struct as st
import numpy as np               
                  
MNIST = {'MY_IMGS':'train-images.idx3-ubyte'}
train_imagesfile = open(MNIST['MY_IMGS'],'rb')
train_imagesfile.seek(0)
magic = st.unpack('>4B',train_imagesfile.read(4))
number_of_images,number_of_rows,number_of_columns=st.unpack('>III',train_imagesfile.read(12))
temp=np.asarray(st.unpack('>'+(number_of_images*number_of_rows*number_of_columns)*'B',train_imagesfile.read(number_of_images*number_of_rows*number_of_columns)))
images_array=temp.reshape(number_of_images,number_of_rows,number_of_columns)

print(images_array)

#print((images_array[4500][10][5]))

import matplotlib.pyplot as plt
plt.imshow(images_array[0,:,:], cmap='gray')
plt.show()

pip install idx2numpy

import numpy as np

R=[]
for img in images_array:
  temp=np.array(img.flatten())
  R.append(temp)

#flattend image array
R=np.array(R)

# Global Mean & Varience

mean=[]

for j in range(0,len(R[0])):
  sum=0
  for i in range(0,len(R)):
    sum =sum+R[i][j]
  sum=sum/len(R)
  mean.append(sum)

mean=np.array(mean)

print((mean))

###Nahiiiiii 

var=[]
for k in range(0,len(R)):
  v=[]
  for item in R[k]:
    j=0
    for item1 in R[k]:
      temp1=(item-mean[k])
      temp2=(item1-mean[j])
      j=j+1
      v.append((temp1*temp2)/(len(R[0])))
  v=np.array(v)
  v=v.reshape(len(R[0]),len(R[0]))
  var.append(v)


var=np.array(var)
print(var)

milo

##Library function of Standard Scalar

from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
scaler.fit(R)

std_data=(scaler.transform(R))

y=(std_data[0].reshape(28,28))
import matplotlib.pyplot as plt
plt.imshow(y[:,:], cmap='gray')
plt.show()

## Mera khud ka standard scalar ##
X=[]
for item in R:
  temp=[]
  for i in range(0,len(R[0])):
    x=item[i]-mean[i]
    temp.append(x)
  temp=np.array(temp)
  X.append(temp) 

std_data=np.array(X)

y=(std_data[0].reshape(28,28))
import matplotlib.pyplot as plt
plt.imshow(y[:,:], cmap='gray')
plt.show()

from scipy.linalg import eigh
import pandas as pd
covariance_matrix=np.cov(R.T)
values, vectors = eigh(covariance_matrix, eigvals=(782,783))

#print((vectors[0][0]))
v0=[]
for i in range(0,len(vectors)):
  v0.append(vectors[i][0])

v0=np.array(v0)

y=(v0.reshape(28,28))
import matplotlib.pyplot as plt
plt.imshow(y[:,:], cmap='gray')
plt.show()


#print(covariance_matrix[45][45])

##For P dimensional reduction####
values, vectors = eigh(covariance_matrix)
values=np.flipud(values)
#vectors=np.flipud(vectors)

eigen_energy=input("Enter eigen energy value in fraction")
eigen_energy=float(eigen_energy)
N=0
for i in range(0,784):
  N=N+values[i]
frac=0
p=0
for i in range(0,784):
  frac=frac+(values[i]/N)
  if frac > eigen_energy:
    p=i
    break

print(p)

import matplotlib.pyplot as plt 
  
Temp=[]
for i in range(0,p):
  Temp.append(vectors[i])

Temp=np.array(Temp)


projected_X = std_data.dot(Temp.T)

y=(vectors[0].reshape(28,28))
import matplotlib.pyplot as plt
plt.imshow(y[:,:], cmap='gray')
plt.show()

y=(std_data[12].reshape(28,28))
import matplotlib.pyplot as plt
plt.imshow(y[:,:], cmap='gray')
plt.show()

import matplotlib.pyplot as plt 
  
Temp=[]
Temp.append(vectors[0])
Temp.append(vectors[1])
Temp=np.array(Temp)


projected_X = std_data.dot(vectors)

X=[]
Y=[]
for i in range(0,len(R)):
  X.append(projected_X[i][0])
  Y.append(projected_X[i][1])

print(X)
print(Y)
#
#plt.scatter(X,Y)
#plt.show()


import pandas as pd
labeled_data = np.vstack((projected_X.T,temp )).T
dataframe = pd.DataFrame(data=labeled_data, columns=("X", "Y", "label"))
print(dataframe.head())


import seaborn as sb
sb.FacetGrid(dataframe, hue="label", size=5).map(plt.scatter, "X","Y").add_legend()
plt.show()

####Supervised Learning FDA Implementation ##############


import struct as st
import numpy as np               
                  
MNIST = {'MY_LABELS':'train-labels.idx1-ubyte'}
train_labelsfile = open(MNIST['MY_LABELS'],'rb')
train_labelsfile.seek(0)
magic = st.unpack('>4B',train_labelsfile.read(4))
number_of_items=st.unpack('>I',train_labelsfile.read(4))
temp=(st.unpack('>'+60000*'B',train_labelsfile.read(60000)))

print(temp)

##here I have divided the pictures according to their labels
classes = [[] for i in range(10)]

for i in range(60000):
  index=temp[i]
  classes[index].append(R[i])
  
for i in range(0,len(classes)):
  classes[i]=np.array(classes[i])
classes=np.array(classes)

S_W = np.cov(classes[0].T)
for i in range(1,10):
  cv = np.cov(classes[i].T)
  
  S_W=S_W+cv

###Making diagonal elements 0 of S
S=np.cov(R.T)
#for i in range(0,784):
#  for j in range(0,784):
#    if i != j:5
#      S[i][j]=0

S_B=S-S_W

import numpy as np 

 
S_W_INV = np.linalg.pinv(S_W.T) 

LHS_MAT = S_W_INV.dot(S_B.T)

from scipy.linalg import eigh

values, vectors = eigh(LHS_MAT, eigvals=(782,783))

projected_X = R.dot(vectors)

X=[]
Y=[]
for i in range(0,len(R)):
  X.append(projected_X[i][0])
  Y.append(projected_X[i][1])



#print(X)
#print(Y)
import pandas as pd
labeled_data_fda = np.vstack((projected_X.T, temp)).T
dataframe = pd.DataFrame(data=labeled_data_fda, columns=("X","Y", "label"))
print(dataframe.head())

# plotting the 2d data points with seaborn
import seaborn as sn
sn.FacetGrid(dataframe, hue="label", size=6).map(plt.scatter, "X", "Y").add_legend()
plt.show()

####LDA####
##################

cov_array=[]
mean=[]
prior=[]

def mean_calc(group):
  
  mean=[]

  for j in range(0,len(group[0])):
    sum=0
    for i in range(0,len(group)):
      sum =sum+group[i][j]
    sum=sum/len(group)
    mean.append(sum)

  mean=np.array(mean)
  return mean

S1 = (len(classes[0])*np.cov(classes[0].T))/len(R)
mean.append(mean_calc(classes[0]))
for i in range(1,10):
  c= (len(classes[i])*(np.cov(classes[i].T)))/len(R)
  S1=S1+c
  mean.append(mean_calc(classes[i]))


for i in range(0,10):
  prior.append(len(classes[i])/60000)

#S_DET=np.linalg.det(np.cov(classes[0].T))
#print(S_DET)

S_INV=np.linalg.pinv(S1.T)
S_DET=np.linalg.det(S1)
print(S_INV)

import struct as st
import numpy as np               
                  
MNIST = {'MY_IMGS':'t10k-images.idx3-ubyte'}
test_imagesfile = open(MNIST['MY_IMGS'],'rb')
test_imagesfile.seek(0)
magic = st.unpack('>4B',test_imagesfile.read(4))
number_of_images,number_of_rows,number_of_columns=st.unpack('>III',test_imagesfile.read(12))
#temp=np.asarray(st.unpack('>'+(number_of_images*number_of_rows*number_of_columns)*'B',test_imagesfile.read(number_of_images*number_of_rows*number_of_columns)))
#images_array_test=temp.reshape(number_of_images,number_of_rows,number_of_columns)
temp=np.asarray(st.unpack('>'+(10000*number_of_rows*number_of_columns)*'B',test_imagesfile.read(10000*number_of_rows*number_of_columns)))
images_array_test=temp.reshape(10000,number_of_rows,number_of_columns)


#print(images_array_test)
import numpy as np

S=[]
for img in images_array_test:
  temp=np.array(img.flatten())
  S.append(temp)

#flattend image array for testing
S=np.array(S)


#####Test Data label Extraction####
import struct as st
import numpy as np               
                  
MNIST = {'MY_LABELS':'t10k-labels.idx1-ubyte'}
test_labelsfile = open(MNIST['MY_LABELS'],'rb')
test_labelsfile.seek(0)
magic = st.unpack('>4B',test_labelsfile.read(4))
number_of_items=st.unpack('>I',test_labelsfile.read(4))
temp1=(st.unpack('>'+10000*'B',test_labelsfile.read(10000)))

print(temp1)

###LDA CODE ####

correct=0


for index in range(0,len(S)):
  G_max=-999
  cls=-1
  for i in range(0,10):
    p1=-0.5 * (S_DET)
    t=(S[index]-mean[i])
    
    q=np.matmul(t.T ,S_INV)
    p2=-0.5 *(np.matmul(q.T,t))

    p3= np.log(prior[i])

    G = p1+p2 +p3
    if(G>G_max):
      G_max=G
      cls=i 
  if temp1[index]==cls:
    print(cls)
    correct =correct+1

#print(S[0])

Accuracy=correct/10000
print(Accuracy)

