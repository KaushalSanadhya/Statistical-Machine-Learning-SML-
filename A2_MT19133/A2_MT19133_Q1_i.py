# -*- coding: utf-8 -*-
"""i.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1h6k55wUibx0UAwOeTZVCiLnHzsFXqvnD
"""

import struct as st
import numpy as np               
                  
MNIST = {'MY_IMGS':'train-images.idx3-ubyte'}
train_imagesfile = open(MNIST['MY_IMGS'],'rb')
train_imagesfile.seek(0)
magic = st.unpack('>4B',train_imagesfile.read(4))
number_of_images,number_of_rows,number_of_columns=st.unpack('>III',train_imagesfile.read(12))
temp=np.asarray(st.unpack('>'+(number_of_images*number_of_rows*number_of_columns)*'B',train_imagesfile.read(number_of_images*number_of_rows*number_of_columns)))
images_array=temp.reshape(number_of_images,number_of_rows,number_of_columns)

print(images_array)

import struct as st
import numpy as np               
                  
MNIST = {'MY_IMGS':'t10k-images.idx3-ubyte'}
test_imagesfile = open(MNIST['MY_IMGS'],'rb')
test_imagesfile.seek(0)
magic = st.unpack('>4B',test_imagesfile.read(4))
number_of_images,number_of_rows,number_of_columns=st.unpack('>III',test_imagesfile.read(12))
#temp=np.asarray(st.unpack('>'+(number_of_images*number_of_rows*number_of_columns)*'B',test_imagesfile.read(number_of_images*number_of_rows*number_of_columns)))
#images_array_test=temp.reshape(number_of_images,number_of_rows,number_of_columns)
temp=np.asarray(st.unpack('>'+(10000*number_of_rows*number_of_columns)*'B',test_imagesfile.read(10000*number_of_rows*number_of_columns)))
images_array_test=temp.reshape(10000,number_of_rows,number_of_columns)


#print(images_array_test)
import numpy as np

S=[]
for img in images_array_test:
  temp=np.array(img.flatten())
  S.append(temp)

#flattend image array for testing
S=np.array(S)
from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
scaler.fit(S)

S=(scaler.transform(S))

import numpy as np

R=[]
for img in images_array:
  temp=np.array(img.flatten())
  R.append(temp)

#flattend image array
R=np.array(R)

# Global Mean & Varience

mean=[]

for j in range(0,len(R[0])):
  sum=0
  for i in range(0,len(R)):
    sum =sum+R[i][j]
  sum=sum/len(R)
  mean.append(sum)

mean=np.array(mean)

print((mean))

## Mera khud ka standard scalar ##
X=[]
for item in R:
  temp=[]
  for i in range(0,len(R[0])):
    x=item[i]-mean[i]
    temp.append(x)
  temp=np.array(temp)
  X.append(temp) 

std_data=np.array(X)

y=(std_data[0].reshape(28,28))
import matplotlib.pyplot as plt
plt.imshow(y[:,:], cmap='gray')
plt.show()

from scipy.linalg import eigh
import pandas as pd
covariance_matrix=np.cov(std_data.T)

##For P dimensional reduction####
values, vectors = eigh(covariance_matrix)
values=np.flipud(values)
#vectors=np.flipud(vectors)

vectors=vectors.T
vectors=np.flipud(vectors)

eigen_energy=input("Enter eigen energy value in fraction")
eigen_energy=float(eigen_energy)
N=0
for i in range(0,784):
  N=N+values[i]
frac=0
p=0
for i in range(0,784):
  frac=frac+(values[i]/N)
  if frac > eigen_energy:
    p=i
    break

print(p)

vect_upd=[]
for i in range(0,p):
  vect_upd.append(vectors[i])
  
vect_upd=np.array(vect_upd)

projected_X = np.matmul(vect_upd,std_data.T)
projected_Y=np.matmul(vect_upd,S.T)

projected_X=projected_X.T
R=projected_X

projected_Y=projected_Y.T
S=projected_Y

print(len(projected_X))
print(len(projected_X[0]))

####Supervised Learning FDA Implementation ##############


import struct as st
import numpy as np               
                  
MNIST = {'MY_LABELS':'train-labels.idx1-ubyte'}
train_labelsfile = open(MNIST['MY_LABELS'],'rb')
train_labelsfile.seek(0)
magic = st.unpack('>4B',train_labelsfile.read(4))
number_of_items=st.unpack('>I',train_labelsfile.read(4))
temp=(st.unpack('>'+60000*'B',train_labelsfile.read(60000)))

print(temp)

##here I have divided the pictures according to their labels
classes = [[] for i in range(10)]

for i in range(60000):
  index=temp[i]
  classes[index].append(R[i])
  
for i in range(0,len(classes)):
  classes[i]=np.array(classes[i])
classes=np.array(classes)

S_W = np.cov(classes[0].T)
for i in range(1,10):
  cv = np.cov(classes[i].T)
  
  S_W=S_W+cv

S=np.cov(R.T)

S_B=S-S_W

import numpy as np 

 
S_W_INV = np.linalg.pinv(S_W.T) 

LHS_MAT = S_W_INV.dot(S_B.T)

from scipy.linalg import eigh

values, vectors = eigh(LHS_MAT)
values=np.flipud(values)
print(len(vectors[0]))
#print((vectors))


vectors=vectors.T
vectors=np.flipud(vectors)

vect_upd=[]
for i in range(0,9):
  vect_upd.append(vectors[i])
vect_upd=np.array(vect_upd)
  

projected_X = R.dot(vect_upd.T)
projected_Y = S.dot(vect_upd.T)

S=projected_Y

####LDA####
##################




classes = [[] for i in range(10)]

for i in range(60000):
  index=temp[i]
  classes[index].append(projected_X[i])
  
for i in range(0,len(classes)):
  classes[i]=np.array(classes[i])
classes=np.array(classes)



cov_array=[]
mean=[]
prior=[]

def mean_calc(group):
  
  mean=[]

  for j in range(0,len(group[0])):
    sum=0
    for i in range(0,len(group)):
      sum =sum+group[i][j]
    sum=sum/len(group)
    mean.append(sum)

  mean=np.array(mean)
  return mean

S1 = (len(classes[0])*np.cov(classes[0].T))/len(R)
mean.append(mean_calc(classes[0]))
for i in range(1,10):
  c= (len(classes[i])*(np.cov(classes[i].T)))/len(R)
  S1=S1+c
  mean.append(mean_calc(classes[i]))


for i in range(0,10):
  prior.append(len(classes[i])/60000)

S_INV=np.linalg.pinv(S1.T)
S_DET=np.linalg.det(S1)








#####Test Data label Extraction####
import struct as st
import numpy as np               
                  
MNIST = {'MY_LABELS':'t10k-labels.idx1-ubyte'}
test_labelsfile = open(MNIST['MY_LABELS'],'rb')
test_labelsfile.seek(0)
magic = st.unpack('>4B',test_labelsfile.read(4))
number_of_items=st.unpack('>I',test_labelsfile.read(4))
temp1=(st.unpack('>'+10000*'B',test_labelsfile.read(10000)))

print(temp1)
print((S_INV))
print((S_DET))

###LDA CODE ####

correct=0


for index in range(0,len(S)):
  G_max=-99999999
  cls=-1
  for i in range(0,10):
    p1=-0.5 * np.log(S_DET)
    t=(S[index]-mean[i])
    
    q=np.matmul(t.T ,S_INV)
    p2=-0.5 *(np.matmul(q.T,t))

    p3= np.log(prior[i])

    G = p1+p2 +p3
    #print(G)
    if(G>G_max):
      G_max=G
      cls=i 
  #print(cls)    
  if temp1[index]==cls:
    #print(cls)
    correct =correct+1

print((correct/10000)*100)